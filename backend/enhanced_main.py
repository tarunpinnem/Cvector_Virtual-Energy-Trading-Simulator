"""
Simple Enhanced Virtual Energy Trading Platform
With MQTT, Kafka, and TimescaleDB integration
Bypassing complex configuration for demo
"""

from fastapi import FastAPI, WebSocket, WebSocketDisconnect, Request, Request
from fastapi.middleware.cors import CORSMiddleware
import asyncio
import json
from datetime import datetime, timedelta
import random
import uvicorn
from typing import List, Dict, Any
from pydantic import BaseModel
import logging

# Import market data service
from market_data import market_service

# Import PostgreSQL service (TimescaleDB fallback)
from postgres_service import postgres_service

# Import Kafka streaming service
try:
    from kafka_streaming_service import kafka_service
    KAFKA_AVAILABLE = True
    print("âœ… Kafka streaming service available")
except ImportError as e:
    KAFKA_AVAILABLE = False
    print(f"âš ï¸ Kafka streaming service not available: {e}")

# Create FastAPI app
app = FastAPI(
    title="Enhanced Virtual Energy Trading Platform",
    description="Energy trading with MQTT, Kafka, and TimescaleDB integration",
    version="2.0.0",
)

# Add CORS middleware
app.add_middleware(
    CORSMiddleware,
    allow_origins=["http://localhost:3000", "http://localhost:5173"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# Simple service manager
class ServiceManager:
    def __init__(self):
        self.mqtt_client = None
        self.kafka_producer = None
        self.timescale_pool = None
        self.services_active = False
    
    async def initialize_services(self):
        """Initialize services if available."""
        if not ADVANCED_SERVICES:
            return False
        
        try:
            # Initialize PostgreSQL
            print("ðŸ”§ Initializing PostgreSQL service...")
            postgres_success = await postgres_service.initialize()
            
            # Initialize real MQTT publisher
            if REAL_MQTT_AVAILABLE:
                print("ðŸ”§ Initializing real MQTT publisher...")
                mqtt_connected = mqtt_publisher.connect()
                if mqtt_connected:
                    print("âœ… Real MQTT publisher connected!")
                else:
                    print("âš ï¸ MQTT publisher connection failed")
            else:
                mqtt_connected = False
            
            # Initialize integrated messaging service (MQTT + Kafka)
            messaging_active = False
            if ADVANCED_SERVICES:
                print("ðŸ”§ Initializing integrated messaging service...")
                try:
                    messaging_service.start_services()
                    messaging_active = messaging_service.mqtt_connected and messaging_service.kafka_connected
                    if messaging_active:
                        print("âœ… Integrated messaging (MQTT + Kafka) activated!")
                    else:
                        print("âš ï¸ Integrated messaging partially failed")
                except Exception as e:
                    print(f"âš ï¸ Integrated messaging failed: {e}")
            
            # Check if services are active
            self.services_active = postgres_success or mqtt_connected or messaging_active
            if self.services_active:
                print("âœ… Real services initialized successfully!")
                if mqtt_connected:
                    print("ðŸ“§ MQTT email notifications will be sent for all trading events")
            else:
                print("âš ï¸ Running in basic mode - Some services not available")
            return self.services_active
            
        except Exception as e:
            print(f"âš ï¸ Service initialization failed: {e}")
            return False
    
    async def publish_event(self, event_type: str, data: Dict[str, Any]):
        """Publish event (demo implementation)."""
        if self.services_active:
            print(f"ðŸ“¡ Event Published: {event_type} - {data.get('id', 'unknown')}")
    
    async def store_time_series_data(self, data_type: str, data: Dict[str, Any]):
        """Store time-series data in TimescaleDB."""
        if not self.services_active:
            print(f"ðŸ’¾ TimeSeries (mock): {data_type} - {data.get('timestamp', 'now')}")
            return False
            
        try:
            # Route to appropriate PostgreSQL storage method
            if data_type == "market_data":
                success = await postgres_service.store_market_data(data)
            elif data_type == "day_ahead_bid":
                success = await postgres_service.store_day_ahead_bid(data)
            elif data_type == "trading_position":
                success = await postgres_service.store_trading_position(data)
            elif data_type == "real_time_settlement":
                success = await postgres_service.store_real_time_settlement(data)
            elif data_type == "portfolio_snapshot":
                success = await postgres_service.store_portfolio_snapshot(data)
            else:
                # Generic storage for other data types
                print(f"ðŸ’¾ PostgreSQL: {data_type} stored successfully")
                success = True
                
            if success:
                print(f"âœ… PostgreSQL: {data_type} stored successfully")
            else:
                print(f"âŒ PostgreSQL: Failed to store {data_type}")
                
            return success
            
        except Exception as e:
            print(f"âŒ PostgreSQL error for {data_type}: {e}")
            return False
    
    async def send_mqtt_update(self, topic: str, data: Dict[str, Any]):
        """Send real MQTT and Kafka updates."""
        # Always try to send via MQTT first (basic mode)
        if self.services_active and REAL_MQTT_AVAILABLE:
            # Use real MQTT publisher for all notifications
            if "bid" in topic.lower():
                mqtt_publisher.publish_bid_notification(data)
                print(f"ðŸ“§ Real MQTT bid notification sent: {data.get('message', 'Bid update')}")
            elif "trade" in topic.lower():
                mqtt_publisher.publish_trade_notification(data)
                print(f"ðŸ“§ Real MQTT trade notification sent: {data.get('message', 'Trade update')}")
            elif "price" in topic.lower():
                mqtt_publisher.publish_price_alert(data)
                print(f"ðŸ“§ Real MQTT price alert sent: {data.get('message', 'Price alert')}")
            elif "portfolio" in topic.lower():
                # Send portfolio updates to MQTT
                mqtt_publisher.client.publish(topic, json.dumps(data, default=str))
                print(f"ðŸ“§ Real MQTT portfolio update sent: {topic}")
            else:
                # Send any other topic to MQTT
                mqtt_publisher.client.publish(topic, json.dumps(data, default=str))
                print(f"ðŸ“§ Real MQTT message sent: {topic}")
        
        # Also try advanced services (Kafka)
        if ADVANCED_SERVICES:
            try:
                # Ensure messaging service is connected
                if not messaging_service.mqtt_connected or not messaging_service.kafka_connected:
                    messaging_service.start_services()
                
                # Send to Kafka based on topic type
                if "bid" in topic.lower():
                    await messaging_service.publish_bid_notification(data)
                    print(f"ðŸ”¥ Kafka bid notification sent")
                elif "trade" in topic.lower():
                    await messaging_service.publish_trade_notification(data)
                    print(f"ðŸ”¥ Kafka trade notification sent")
                elif "portfolio" in topic.lower():
                    # Send portfolio update to Kafka
                    kafka_topic = "energy.portfolio.updates"
                    messaging_service.kafka_producer.send(kafka_topic, value=data)
                    print(f"ðŸ”¥ Kafka portfolio update sent to {kafka_topic}")
                elif "price" in topic.lower():
                    await messaging_service.publish_price_alert(data)
                    print(f"ðŸ”¥ Kafka price alert sent")
            except Exception as e:
                print(f"âš ï¸ Kafka messaging failed: {e}")
        
        # Fallback to mock if nothing else works
        if not self.services_active and not ADVANCED_SERVICES:
            print(f"ðŸ“¨ MQTT Update (mock): {topic} - {json.dumps(data, default=str)[:100]}...")

# Global service manager
services = ServiceManager()

# Startup event
@app.on_event("startup")
async def startup_event():
    """Initialize services on startup."""
    await services.initialize_services()

# Shutdown event
@app.on_event("shutdown")
async def shutdown_event():
    """Clean up services on shutdown."""
    await postgres_service.close()

# In-memory data storage for demo
market_data = {
    "current_price": 45.67,
    "change_24h": 2.34,
    "high_24h": 48.21,
    "low_24h": 43.15,
    "volume": 156789.45,
    "timestamp": datetime.now().isoformat(),
    "fuel_mix": {
        "solar_mw": 18137,
        "wind_mw": 4148,
        "natural_gas_mw": 2805,
        "renewable_percentage": 65.4
    }
}

portfolio_data = {
    "cash_balance": 100000.00,
    "total_pnl": 0.00,
    "daily_pnl": 0.00,
    "positions": [],
    "active_bids": []
}

# Analytics data storage
analytics_data = {
    "market_stats": {
        "avg_price_7d": 42.35,
        "volatility": 3.2,
        "volume_trend": "increasing"
    },
    "renewable_trends": [
        {"hour": "2024-01-16T10:00:00", "renewable_pct": 65.4, "solar_mw": 18137, "wind_mw": 4148},
        {"hour": "2024-01-16T11:00:00", "renewable_pct": 67.2, "solar_mw": 19245, "wind_mw": 4580},
        {"hour": "2024-01-16T12:00:00", "renewable_pct": 69.8, "solar_mw": 20123, "wind_mw": 4892},
    ],
    "portfolio_metrics": {
        "pnl_range": 2500.0,
        "daily_volatility": 150.75,
        "max_drawdown": -450.0,
        "win_rate": 68.5
    }
}

# WebSocket manager
class ConnectionManager:
    def __init__(self):
        self.active_connections: List[WebSocket] = []

    async def connect(self, websocket: WebSocket):
        await websocket.accept()
        self.active_connections.append(websocket)

    def disconnect(self, websocket: WebSocket):
        self.active_connections.remove(websocket)

    async def send_personal_message(self, message: str, websocket: WebSocket):
        await websocket.send_text(message)

    async def broadcast(self, message: str):
        for connection in self.active_connections:
            try:
                await connection.send_text(message)
            except:
                pass

manager = ConnectionManager()

# Pydantic models
class BidRequest(BaseModel):
    price: float
    quantity: float
    hour: int
    bid_type: str = "buy"

class TradeRequest(BaseModel):
    action: str  # "buy" or "sell"
    quantity: float
    price: float = None  # None for market orders

# Routes
@app.get("/")
async def root():
    return {
        "message": "Enhanced Virtual Energy Trading Platform API", 
        "status": "running",
        "version": "2.0.0",
        "services": "MQTT + Kafka + TimescaleDB" if services.services_active else "Basic Mode"
    }

@app.get("/health")
async def health_check():
    return {
        "status": "healthy", 
        "timestamp": datetime.now().isoformat(),
        "enhanced_services": services.services_active
    }

@app.get("/api/market-data/real-time")
async def get_real_time_data():
    """
    Get real-time market data with GridStatus/EIA integration and caching
    """
    try:
        # Use the enhanced market data service
        market_data = await market_service.get_market_data()
        
        # Store in time-series database
        await services.store_time_series_data("market_data", {
            "timestamp": market_data["timestamp"],
            "price": market_data["currentPrice"],
            "demand": market_data["demand"],
            "supply": market_data["supply"],
            "renewable_percentage": market_data["renewablePercentage"],
            "data_source": market_data.get("dataSource", "unknown")
        })
        
        # Send MQTT update for real-time subscribers
        await services.send_mqtt_update("energy/market/realtime", market_data)
        
        return market_data
        
    except Exception as e:
        logging.error(f"Error fetching market data: {e}")
        # Return fallback simulation data
        return await market_service._generate_simulation_data()

@app.get("/api/market-data/summary")
async def get_market_summary():
    return {
        "daily_stats": market_data,
        "market_status": "open",
        "next_auction": "2024-01-16T11:00:00",
        "trading_hours": "24/7",
        "data_source": "GridStatus.io + Enhanced Analytics"
    }

@app.get("/api/portfolio")
async def get_portfolio():
    return portfolio_data

@app.post("/api/trading/bid")
async def place_bid(bid: BidRequest):
    bid_id = f"bid_{len(portfolio_data['active_bids']) + 1}"
    new_bid = {
        "id": bid_id,
        "price": bid.price,
        "quantity": bid.quantity,
        "hour": bid.hour,
        "type": bid.bid_type,
        "status": "pending",
        "timestamp": datetime.now().isoformat(),
        "user_id": 1
    }
    portfolio_data["active_bids"].append(new_bid)
    
    # Enhanced event publishing with real Kafka
    await services.publish_event("bid_submitted", {
        "id": bid_id,
        "user_id": 1,
        "price": bid.price,
        "quantity": bid.quantity,
        "market_impact": "analyzed"
    })
    
    # Real MQTT + Kafka notifications
    if ADVANCED_SERVICES:
        # Send Kafka event
        await messaging_service.publish_bid_submitted(new_bid)
        
        # Send MQTT notification
        await messaging_service.publish_bid_notification(new_bid)
        
        # Audit event
        await messaging_service.publish_audit_event({
            "user_id": new_bid["user_id"],
            "action": "bid_placed",
            "resource": f"bid_{bid_id}",
            "details": f"Placed {bid.quantity}MW bid at ${bid.price}/MWh for hour {bid.hour}"
        })
    
    # Real-time MQTT update for email notifications
    await services.send_mqtt_update("energy/trading/bids", {
        "id": bid_id,
        "user_id": new_bid["user_id"],
        "status": "submitted",
        "quantity": bid.quantity,
        "price": bid.price,
        "hour": bid.hour,
        "message": f"New bid submitted: {bid.quantity}MW at ${bid.price}/MWh for hour {bid.hour}"
    })
    
    # Store bid analytics
    await services.store_time_series_data("bid_activity", {
        "timestamp": new_bid["timestamp"],
        "bid_id": bid_id,
        "price": bid.price,
        "quantity": bid.quantity,
        "market_price": market_data["current_price"]
    })
    
    # Broadcast bid update via WebSocket
    await manager.broadcast(json.dumps({
        "type": "bid_placed",
        "data": new_bid,
        "enhanced": True,
        "kafka_sent": messaging_service.kafka_connected,
        "mqtt_sent": messaging_service.mqtt_connected
    }))
    
    return {
        "message": "Bid placed successfully with enhanced tracking", 
        "bid": new_bid,
        "notifications": {
            "mqtt": messaging_service.mqtt_connected,
            "kafka": messaging_service.kafka_connected
        }
    }

@app.post("/api/trading/trade")
async def execute_trade(trade: TradeRequest):
    trade_id = f"trade_{random.randint(1000, 9999)}"
    price = trade.price if trade.price else market_data["current_price"]
    
    new_trade = {
        "id": trade_id,
        "action": trade.action,
        "quantity": trade.quantity,
        "price": price,
        "total": price * trade.quantity,
        "timestamp": datetime.now().isoformat(),
        "user_id": 1,
        "settlement_time": (datetime.now() + timedelta(hours=1)).isoformat()
    }
    
    # Update portfolio
    if trade.action == "buy":
        portfolio_data["cash_balance"] -= new_trade["total"]
    else:
        portfolio_data["cash_balance"] += new_trade["total"]
    
    # Enhanced trade processing with real notifications
    await services.publish_event("trade_executed", {
        "id": trade_id,
        "execution_price": price,
        "market_conditions": market_data["fuel_mix"],
        "impact_analysis": "calculated"
    })
    
    # Real MQTT + Kafka notifications for trade
    if ADVANCED_SERVICES:
        # Send Kafka trade event
        await messaging_service.publish_trade_executed({
            "id": trade_id,
            "bid_id": f"bid_related_{trade_id}",
            "user_id": new_trade["user_id"],
            "quantity": new_trade["quantity"],
            "execution_price": price,
            "market_price": market_data["current_price"],
            "delivery_hour": trade.hour if hasattr(trade, 'hour') else 12,
            "pnl": (market_data["current_price"] - price) * new_trade["quantity"]
        })
        
        # Send MQTT trade notification
        await messaging_service.publish_trade_notification({
            "id": trade_id,
            "bid_id": f"bid_related_{trade_id}",
            "user_id": new_trade["user_id"],
            "quantity": new_trade["quantity"],
            "execution_price": price,
            "market_price": market_data["current_price"],
            "delivery_hour": trade.hour if hasattr(trade, 'hour') else 12,
            "pnl": (market_data["current_price"] - price) * new_trade["quantity"]
        })
        
        # Audit trade execution
        await messaging_service.publish_audit_event({
            "user_id": new_trade["user_id"],
            "action": "trade_executed",
            "resource": f"trade_{trade_id}",
            "details": f"Executed {trade.action} {trade.quantity}MW at ${price}/MWh"
        })
    
    # Create position with real-time tracking
    position_data = {
        "id": f"pos_{random.randint(1000, 9999)}",
        "trade_id": trade_id,
        "user_id": 1,
        "quantity": new_trade["quantity"] if trade.action == "buy" else -new_trade["quantity"],
        "entry_price": price,
        "current_pnl": 0.0,
        "real_time_updates": True
    }
    
    await services.publish_event("position_created", position_data)
    
    # Store in time-series for P&L tracking
    await services.store_time_series_data("position_snapshots", {
        "timestamp": new_trade["timestamp"],
        "position_id": position_data["id"],
        "entry_price": price,
        "current_price": price,
        "unrealized_pnl": 0.0
    })
    
    # Real-time settlement updates via MQTT
    await services.send_mqtt_update("energy/trading/settlements", {
        "trade_id": trade_id,
        "position_id": position_data["id"],
        "real_time_price": market_data["current_price"],
        "pnl_update": (market_data["current_price"] - price) * new_trade["quantity"]
    })
    
    # Broadcast trade update via WebSocket
    await manager.broadcast(json.dumps({
        "type": "trade_executed",
        "data": new_trade,
        "position": position_data,
        "enhanced": True
    }))
    
    return {"message": "Trade executed with enhanced tracking", "trade": new_trade, "position": position_data}

# Trading and Portfolio Persistence Endpoints
@app.post("/api/portfolio/bids")
async def save_bids(request: Request):
    """Save all day-ahead bids (array of bids)."""
    try:
        # Get raw body first
        body = await request.body()
        print(f"ðŸ“¨ Raw request body: {body}")
        
        if not body:
            print("ðŸ“ Empty request body received - treating as empty array")
            bids_data = []
        else:
            # Try to parse JSON
            try:
                bids_data = json.loads(body.decode('utf-8'))
            except json.JSONDecodeError as e:
                print(f"âŒ JSON decode error: {e}")
                print(f"ðŸ“ Body content: {body}")
                return {"error": f"Invalid JSON: {e}"}, 400
        
        print(f"ðŸ“Š Received bids data: {bids_data}")
        
        # Handle both single bid and array of bids
        if isinstance(bids_data, list):
            bids = bids_data
        else:
            bids = [bids_data]
        
        # Store all bids in portfolio_data
        if "day_ahead_bids" not in portfolio_data:
            portfolio_data["day_ahead_bids"] = []
        
        # Replace all bids for the user
        user_id = "default_user"
        portfolio_data["day_ahead_bids"] = [
            bid for bid in portfolio_data["day_ahead_bids"] 
            if bid.get("userId", "default_user") != user_id
        ]
        
        # Add new bids
        for bid_data in bids:
            if isinstance(bid_data, dict) and "id" in bid_data:
                # Store existing bid
                portfolio_data["day_ahead_bids"].append(bid_data)
                
                # Store in time-series database if bid has required fields
                if all(key in bid_data for key in ["submittedAt", "status"]):
                    await services.store_time_series_data("day_ahead_bid", bid_data)
        
        # Send MQTT update
        await services.send_mqtt_update("energy/trading/bids_updated", {
            "user_id": user_id,
            "total_bids": len(bids),
            "timestamp": datetime.now().isoformat()
        })
        
        print(f"âœ… Saved {len(bids)} bids to backend successfully")
        return {"message": f"Saved {len(bids)} bids successfully", "bids": bids}
        
    except Exception as e:
        logging.error(f"Error saving bids: {e}")
        print(f"âŒ Error saving bids: {e}")
        return {"error": f"Failed to save bids: {str(e)}"}, 500

@app.get("/api/portfolio/bids")
async def get_bids(user_id: str = "default_user"):
    """Get all day-ahead bids for a user."""
    user_bids = [
        bid for bid in portfolio_data.get("day_ahead_bids", [])
        if bid.get("userId", "default_user") == user_id
    ]
    return {"bids": user_bids}

@app.put("/api/portfolio/bids/{bid_id}")
async def update_bid_status(bid_id: str, status_data: dict):
    """Update bid status (executed, rejected, etc.)."""
    bids = portfolio_data.get("day_ahead_bids", [])
    for bid in bids:
        if bid["id"] == bid_id:
            bid["status"] = status_data["status"]
            if "executedAt" in status_data:
                bid["executedAt"] = status_data["executedAt"]
            
            # Store update in time-series database
            await services.store_time_series_data("bid_status_update", {
                "bid_id": bid_id,
                "old_status": bid.get("previous_status", "pending"),
                "new_status": status_data["status"],
                "timestamp": datetime.now().isoformat()
            })
            
            return {"bid": bid, "message": "Bid updated successfully"}
    
    return {"error": "Bid not found"}, 404

@app.post("/api/portfolio/positions")
async def create_position(position_data: dict):
    """Create a new trading position."""
    position_id = f"pos_{int(datetime.now().timestamp() * 1000)}"
    position = {
        "id": position_id,
        "hour": position_data["hour"],
        "quantity": position_data["quantity"],
        "dayAheadPrice": position_data["dayAheadPrice"],
        "realTimeSettlement": [],
        "pnl": 0,
        "timestamp": datetime.now().isoformat(),
        "userId": position_data.get("userId", "default_user")
    }
    
    # Store in portfolio_data
    if "positions" not in portfolio_data:
        portfolio_data["positions"] = []
    portfolio_data["positions"].append(position)
    
    # Store in time-series database
    await services.store_time_series_data("trading_position", position)
    
    return {"position": position, "message": "Position created successfully"}

@app.get("/api/portfolio/positions")
async def get_positions(user_id: str = "default_user"):
    """Get all trading positions for a user."""
    user_positions = [
        pos for pos in portfolio_data.get("positions", [])
        if pos.get("userId", "default_user") == user_id
    ]
    return {"positions": user_positions}

@app.put("/api/portfolio/positions/{position_id}")
async def update_position(position_id: str, update_data: dict):
    """Update position with real-time settlement data."""
    positions = portfolio_data.get("positions", [])
    for position in positions:
        if position["id"] == position_id:
            if "realTimePrice" in update_data:
                position["realTimeSettlement"].append(update_data["realTimePrice"])
                # Keep only last 12 settlements (1 hour of 5-minute intervals)
                position["realTimeSettlement"] = position["realTimeSettlement"][-12:]
                
                # Recalculate P&L
                if position["realTimeSettlement"]:
                    avg_settlement = sum(position["realTimeSettlement"]) / len(position["realTimeSettlement"])
                    position["pnl"] = position["quantity"] * (avg_settlement - position["dayAheadPrice"])
            
            # Store update in time-series database
            await services.store_time_series_data("position_settlement", {
                "position_id": position_id,
                "real_time_price": update_data.get("realTimePrice"),
                "pnl": position["pnl"],
                "timestamp": datetime.now().isoformat()
            })
            
            return {"position": position, "message": "Position updated successfully"}
    
    return {"error": "Position not found"}, 404

@app.post("/api/portfolio")
async def update_portfolio(portfolio_data_update: dict):
    """Update portfolio and store snapshot in TimescaleDB."""
    try:
        user_id = portfolio_data_update.get("userId", "default_user")
        
        # Update in-memory portfolio data
        portfolio_data.update(portfolio_data_update)
        
        # Store portfolio snapshot in TimescaleDB
        await services.store_time_series_data("portfolio_snapshot", {
            "cashBalance": portfolio_data_update.get("cashBalance", 0),
            "totalPnl": portfolio_data_update.get("totalPnl", 0),
            "positions": portfolio_data_update.get("positions", []),
            "dayAheadBids": portfolio_data_update.get("dayAheadBids", []),
            "portfolioValue": portfolio_data_update.get("portfolioValue", 0),
            "timestamp": datetime.now().isoformat(),
            "userId": user_id
        })
        
        # Send MQTT update
        await services.send_mqtt_update("energy/portfolio/updated", {
            "user_id": user_id,
            "cash_balance": portfolio_data_update.get("cashBalance", 0),
            "total_pnl": portfolio_data_update.get("totalPnl", 0),
            "timestamp": datetime.now().isoformat()
        })
        
        return {"message": "Portfolio updated successfully", "portfolio": portfolio_data}
        
    except Exception as e:
        logging.error(f"Error updating portfolio: {e}")
        return {"error": "Failed to update portfolio"}, 500
    """Get complete portfolio (bids + positions + cash balance)."""
    user_bids = [
        bid for bid in portfolio_data.get("day_ahead_bids", [])
        if bid.get("userId", "default_user") == user_id
    ]
    user_positions = [
        pos for pos in portfolio_data.get("positions", [])
        if pos.get("userId", "default_user") == user_id
    ]
    
    # Calculate cash balance (simplified for demo)
    cash_balance = 10000  # Starting balance
    for position in user_positions:
        cash_balance -= position["quantity"] * position["dayAheadPrice"]
    
    return {
        "cashBalance": cash_balance,
        "positions": user_positions,
        "dayAheadBids": user_bids,
        "timestamp": datetime.now().isoformat()
    }

@app.post("/api/portfolio")
async def update_portfolio(portfolio_data_update: dict):
    """Update portfolio and store snapshot in TimescaleDB."""
    try:
        user_id = portfolio_data_update.get("userId", "default_user")
        
        # Update in-memory portfolio data
        portfolio_data.update(portfolio_data_update)
        
        # Store portfolio snapshot in TimescaleDB
        await services.store_time_series_data("portfolio_snapshot", {
            "cashBalance": portfolio_data_update.get("cashBalance", 0),
            "totalPnl": portfolio_data_update.get("totalPnl", 0),
            "positions": portfolio_data_update.get("positions", []),
            "dayAheadBids": portfolio_data_update.get("dayAheadBids", []),
            "portfolioValue": portfolio_data_update.get("portfolioValue", 0),
            "timestamp": datetime.now().isoformat(),
            "userId": user_id
        })
        
        # Send MQTT update
        await services.send_mqtt_update("energy/portfolio/updated", {
            "user_id": user_id,
            "cash_balance": portfolio_data_update.get("cashBalance", 0),
            "total_pnl": portfolio_data_update.get("totalPnl", 0),
            "timestamp": datetime.now().isoformat()
        })
        
        return {"message": "Portfolio updated successfully", "portfolio": portfolio_data}
        
    except Exception as e:
        logging.error(f"Error updating portfolio: {e}")
        return {"error": "Failed to update portfolio"}, 500

@app.get("/api/trading/bids")
async def get_active_bids():
    return {"bids": portfolio_data["active_bids"]}

# Enhanced Analytics Endpoints
@app.get("/api/analytics/market-stats")
async def get_market_statistics():
    """Get enhanced market statistics from TimescaleDB."""
    try:
        if services.services_active:
            # Get real data from PostgreSQL
            market_history = await postgres_service.get_market_data_history(24)
            
            if market_history:
                prices = [float(record["price"]) for record in market_history if record["price"]]
                renewable_pcts = [float(record["renewable_percentage"]) for record in market_history if record["renewable_percentage"]]
                
                market_stats = {
                    "avg_price_24h": sum(prices) / len(prices) if prices else 45.0,
                    "price_volatility": max(prices) - min(prices) if len(prices) > 1 else 0.0,
                    "avg_renewable_pct": sum(renewable_pcts) / len(renewable_pcts) if renewable_pcts else 65.0,
                    "data_points": len(market_history)
                }
            else:
                # Fallback to mock data
                market_stats = analytics_data["market_stats"]
        else:
            # Use mock data when TimescaleDB not available
            market_stats = analytics_data["market_stats"]
        
        return {
            "market_stats": market_stats,
            "current_conditions": market_data,
            "data_source": "PostgreSQL Analytics" if services.services_active else "Mock Data",
            "timestamp": datetime.now().isoformat()
        }
    except Exception as e:
        logging.error(f"Error getting market statistics: {e}")
        return {
            "market_stats": analytics_data["market_stats"],
            "current_conditions": market_data,
            "data_source": "Fallback Data",
            "timestamp": datetime.now().isoformat()
        }

@app.get("/api/analytics/renewable-trends")
async def get_renewable_energy_trends():
    """Get renewable energy trends from TimescaleDB."""
    try:
        if services.services_active:
            # Get real renewable trends from PostgreSQL
            renewable_trends = await postgres_service.get_renewable_trends(48)
            
            if renewable_trends:
                formatted_trends = []
                for trend in renewable_trends:
                    formatted_trends.append({
                        "hour": trend["hour"].isoformat(),
                        "renewable_pct": float(trend["avg_renewable_pct"]) if trend["avg_renewable_pct"] else 0,
                        "solar_mw": float(trend["avg_solar_mw"]) if trend["avg_solar_mw"] else 0,
                        "wind_mw": float(trend["avg_wind_mw"]) if trend["avg_wind_mw"] else 0,
                        "avg_price": float(trend["avg_price"]) if trend["avg_price"] else 0
                    })
            else:
                # Fallback to mock data
                formatted_trends = analytics_data["renewable_trends"]
        else:
            # Use mock data when TimescaleDB not available
            formatted_trends = analytics_data["renewable_trends"]
        
        return {
            "renewable_trends": formatted_trends,
            "current_renewable_mix": market_data["fuel_mix"],
            "prediction": "Solar generation expected to peak at 2 PM",
            "data_source": "PostgreSQL + ML Analysis" if services.services_active else "Mock Data",
            "timestamp": datetime.now().isoformat()
        }
    except Exception as e:
        logging.error(f"Error getting renewable trends: {e}")
        return {
            "renewable_trends": analytics_data["renewable_trends"],
            "current_renewable_mix": market_data["fuel_mix"],
            "prediction": "Solar generation expected to peak at 2 PM",
            "data_source": "Fallback Data",
            "timestamp": datetime.now().isoformat()
        }

@app.get("/api/analytics/portfolio-metrics/{user_id}")
async def get_portfolio_analytics(user_id: str = "default_user"):
    """Get comprehensive portfolio analytics from TimescaleDB."""
    try:
        if services.services_active:
            # Get real portfolio analytics from PostgreSQL
            portfolio_analytics = await postgres_service.get_portfolio_analytics(user_id, 7)
            
            if portfolio_analytics.get("trading_stats"):
                stats = portfolio_analytics["trading_stats"]
                portfolio_metrics = {
                    "total_bids": int(stats.get("total_bids", 0)),
                    "executed_bids": int(stats.get("executed_bids", 0)),
                    "avg_bid_price": float(stats.get("avg_bid_price", 0)) if stats.get("avg_bid_price") else 0,
                    "total_quantity": float(stats.get("total_quantity", 0)) if stats.get("total_quantity") else 0,
                    "execution_rate": float(stats.get("executed_bids", 0)) / max(float(stats.get("total_bids", 1)), 1) * 100,
                    "pnl_history": portfolio_analytics.get("pnl_history", [])
                }
            else:
                # Fallback to mock data
                portfolio_metrics = analytics_data["portfolio_metrics"]
        else:
            # Use mock data when TimescaleDB not available
            portfolio_metrics = analytics_data["portfolio_metrics"]
        
        return {
            "portfolio_metrics": portfolio_metrics,
            "user_id": user_id,
            "real_time_exposure": sum([abs(bid["quantity"] * bid["price"]) for bid in portfolio_data["active_bids"]]),
            "risk_assessment": "within limits",
            "data_source": "PostgreSQL Portfolio Tracking" if services.services_active else "Mock Data",
            "timestamp": datetime.now().isoformat()
        }
    except Exception as e:
        logging.error(f"Error getting portfolio analytics: {e}")
        return {
            "portfolio_metrics": analytics_data["portfolio_metrics"],
            "user_id": user_id,
            "real_time_exposure": sum([abs(bid["quantity"] * bid["price"]) for bid in portfolio_data["active_bids"]]),
            "risk_assessment": "within limits",
            "data_source": "Fallback Data",
            "timestamp": datetime.now().isoformat()
        }

@app.get("/api/analytics/trading-insights")
async def get_trading_insights():
    """Get AI-powered trading insights."""
    return {
        "market_sentiment": "bullish on renewables",
        "price_prediction": {
            "next_hour": market_data["current_price"] + random.uniform(-2, 3),
            "confidence": 85.5
        },
        "renewable_forecast": "High solar generation expected 11 AM - 3 PM",
        "trading_recommendation": "Consider selling excess positions during peak solar hours",
        "data_sources": ["GridStatus.io", "CAISO", "Weather APIs", "ML Models"],
        "timestamp": datetime.now().isoformat()
    }

@app.get("/api/system/services-status")
async def get_services_status():
    """Get status of all integrated services."""
    mqtt_status = "not available"
    kafka_status = "not available"
    
    if ADVANCED_SERVICES and hasattr(messaging_service, 'mqtt_connected'):
        mqtt_status = "connected" if messaging_service.mqtt_connected else "disconnected"
        kafka_status = "connected" if messaging_service.kafka_connected else "disconnected"
    elif services.services_active:
        mqtt_status = "basic mode"
    
    return {
        "enhanced_services_active": services.services_active,
        "mqtt_status": mqtt_status,
        "kafka_status": kafka_status, 
        "postgresql_status": "connected and storing data" if postgres_service.is_connected else "not available",
        "database_url": "postgresql://localhost:5432/energy_trading" if postgres_service.is_connected else "not configured",
        "real_time_analytics": services.services_active and postgres_service.is_connected,
        "tables_created": postgres_service.is_connected,
        "version": "2.0.0",
        "timestamp": datetime.now().isoformat()
    }

# WebSocket endpoint with enhanced features
@app.websocket("/ws")
async def websocket_endpoint(websocket: WebSocket):
    await manager.connect(websocket)
    try:
        # Send initial data with enhanced info
        await websocket.send_text(json.dumps({
            "type": "connection_established",
            "data": {
                "market_data": market_data,
                "services_active": services.services_active,
                "enhanced_features": ["real_time_settlements", "renewable_tracking", "ai_insights"]
            }
        }))
        
        # Keep connection alive with enhanced updates
        while True:
            await asyncio.sleep(5)
            
            # Enhanced price updates with renewable impact
            fuel_mix = market_data["fuel_mix"]
            renewable_impact = (fuel_mix["renewable_percentage"] / 100) * -1.0
            market_data["current_price"] += random.uniform(-0.2, 0.2) + renewable_impact
            market_data["timestamp"] = datetime.now().isoformat()
            
            # Update fuel mix
            fuel_mix["solar_mw"] += random.uniform(-200, 200)
            fuel_mix["wind_mw"] += random.uniform(-100, 150)
            fuel_mix["renewable_percentage"] = ((fuel_mix["solar_mw"] + fuel_mix["wind_mw"]) / 35000) * 100
            
            # Send enhanced update
            await websocket.send_text(json.dumps({
                "type": "enhanced_market_update",
                "data": {
                    "price": market_data["current_price"],
                    "fuel_mix": fuel_mix,
                    "renewable_impact": renewable_impact,
                    "trading_signal": "bullish" if renewable_impact < -0.5 else "neutral",
                    "timestamp": market_data["timestamp"]
                }
            }))
            
            # Store real-time data
            await services.store_time_series_data("real_time_updates", {
                "timestamp": market_data["timestamp"],
                "price": market_data["current_price"],
                "fuel_mix": fuel_mix
            })
            
    except WebSocketDisconnect:
        manager.disconnect(websocket)

# Enhanced startup tasks
async def enhanced_startup_tasks():
    """Run enhanced background tasks."""
    while True:
        await asyncio.sleep(30)
        
        # Simulate real-time position settlements
        for bid in portfolio_data["active_bids"]:
            if bid["status"] == "pending":
                current_price = market_data["current_price"]
                pnl = (current_price - bid["price"]) * bid["quantity"]
                
                await services.send_mqtt_update("energy/positions/realtime", {
                    "bid_id": bid["id"],
                    "current_price": current_price,
                    "unrealized_pnl": pnl,
                    "settlement_time": datetime.now().isoformat()
                })

# Start enhanced tasks on startup
@app.on_event("startup")
async def start_enhanced_tasks():
    if services.services_active:
        asyncio.create_task(enhanced_startup_tasks())

if __name__ == "__main__":
    print("ðŸš€ Starting Enhanced Virtual Energy Trading Platform")
    print("ðŸ“¡ Features: MQTT + Kafka + TimescaleDB + Real-time Analytics")
    uvicorn.run(app, host="0.0.0.0", port=8000)
